#!/usr/bin/env node

/**
 * VAD è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬
 * ä½¿ç”¨æµ‹è¯•éŸ³é¢‘æ–‡ä»¶éªŒè¯ VAD çš„æ£€æµ‹å’Œåˆ‡åˆ†èƒ½åŠ›
 */

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// VAD é…ç½® (ä¸ useVADRecording.ts ä¿æŒä¸€è‡´)
const VAD_CONFIG = {
    speechThreshold: 0.1,
    silenceThreshold: 0.35,
    minSpeechDurationMs: 200,
    minSilenceDurationMs: 500,
};

const SAMPLE_RATE = 16000;
const BUFFER_SIZE = 2048;
const BUFFER_SIZE_MS = Math.floor(BUFFER_SIZE * 1000 / SAMPLE_RATE);

console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
console.log('         VAD è‡ªåŠ¨åŒ–æµ‹è¯• - éŸ³é¢‘æ–‡ä»¶æ¨¡å¼');
console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

// è¯»å– WAV æ–‡ä»¶å¹¶æå– PCM æ•°æ®
function readWavFile(filePath) {
    console.log(`ğŸ“‚ è¯»å–éŸ³é¢‘æ–‡ä»¶: ${filePath}`);

    const buffer = fs.readFileSync(filePath);

    // ç®€å• WAV è§£æ (å‡è®¾æ ‡å‡†æ ¼å¼)
    const dataOffset = 44; // æ ‡å‡† WAV å¤´éƒ¨å¤§å°
    const pcmData = buffer.slice(dataOffset);

    // è½¬æ¢ä¸º Float32Array (å‡è®¾æ˜¯ 16-bit PCM)
    const samples = new Int16Array(
        pcmData.buffer,
        pcmData.byteOffset,
        pcmData.byteLength / 2
    );

    const float32 = new Float32Array(samples.length);
    for (let i = 0; i < samples.length; i++) {
        float32[i] = samples[i] / 32768.0; // å½’ä¸€åŒ–åˆ° [-1, 1]
    }

    const durationSec = float32.length / SAMPLE_RATE;
    console.log(`âœ… éŸ³é¢‘åŠ è½½å®Œæˆ: ${float32.length} æ ·æœ¬, ${durationSec.toFixed(2)}ç§’\n`);

    return float32;
}

// æ¨¡æ‹Ÿ VAD æ£€æµ‹ (ç®€åŒ–ç‰ˆï¼Œä½¿ç”¨èƒ½é‡æ£€æµ‹)
function simpleVAD(audioChunk) {
    // è®¡ç®— RMS èƒ½é‡
    let sum = 0;
    for (let i = 0; i < audioChunk.length; i++) {
        sum += audioChunk[i] * audioChunk[i];
    }
    const rms = Math.sqrt(sum / audioChunk.length);

    // ç®€å•çš„èƒ½é‡åˆ°æ¦‚ç‡æ˜ å°„
    // RMS > 0.05 â†’ é«˜è¯­éŸ³æ¦‚ç‡
    // RMS < 0.01 â†’ ä½è¯­éŸ³æ¦‚ç‡
    let speechProb;
    if (rms > 0.05) {
        speechProb = 0.8;
    } else if (rms > 0.02) {
        speechProb = 0.5;
    } else if (rms > 0.01) {
        speechProb = 0.2;
    } else {
        speechProb = 0.05;
    }

    return { speechProb, rms };
}

// æ‰§è¡Œ VAD æµ‹è¯•
async function testVAD(audioData) {
    console.log('ğŸ¯ å¼€å§‹ VAD æµ‹è¯•...\n');
    console.log(`é…ç½®ä¿¡æ¯:`);
    console.log(`  - è¯­éŸ³é˜ˆå€¼: ${VAD_CONFIG.speechThreshold}`);
    console.log(`  - é™éŸ³é˜ˆå€¼: ${VAD_CONFIG.silenceThreshold}`);
    console.log(`  - æœ€å°é™éŸ³æ—¶é•¿: ${VAD_CONFIG.minSilenceDurationMs}ms`);
    console.log(`  - ç¼“å†²åŒºå¤§å°: ${BUFFER_SIZE} (${BUFFER_SIZE_MS}ms)\n`);

    console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n');

    let speechBuffer = [];
    let silenceFrames = 0;
    let speechFrames = 0;
    let isSpeaking = false;
    let chunkCount = 0;

    const totalFrames = Math.floor(audioData.length / BUFFER_SIZE);
    let lastLogTime = Date.now();

    for (let i = 0; i < totalFrames; i++) {
        const start = i * BUFFER_SIZE;
        const end = Math.min(start + BUFFER_SIZE, audioData.length);
        const chunk = audioData.slice(start, end);

        if (chunk.length < BUFFER_SIZE) break;

        // æ¨¡æ‹Ÿ VAD æ£€æµ‹
        const { speechProb, rms } = simpleVAD(chunk);

        // æ¯ç§’è¾“å‡ºä¸€æ¬¡è¿›åº¦
        const now = Date.now();
        if (now - lastLogTime > 1000) {
            const progress = ((i / totalFrames) * 100).toFixed(1);
            const currentTime = (i * BUFFER_SIZE / SAMPLE_RATE).toFixed(1);
            console.log(`â±ï¸  è¿›åº¦: ${progress}% | æ—¶é—´: ${currentTime}s | RMS: ${rms.toFixed(4)} | æ¦‚ç‡: ${speechProb.toFixed(3)} | åˆ‡ç‰‡: ${chunkCount}`);
            lastLogTime = now;
        }

        if (speechProb >= VAD_CONFIG.speechThreshold) {
            // æ£€æµ‹åˆ°è¯­éŸ³
            speechFrames++;
            silenceFrames = 0;

            if (!isSpeaking && speechFrames >= 2) {
                isSpeaking = true;
                const timestamp = (i * BUFFER_SIZE / SAMPLE_RATE).toFixed(2);
                console.log(`\nğŸ”Š [${timestamp}s] å¼€å§‹è¯´è¯ (prob=${speechProb.toFixed(3)}, rms=${rms.toFixed(4)})`);
            }

            speechBuffer.push(chunk);

        } else if (speechProb < VAD_CONFIG.silenceThreshold) {
            // æ£€æµ‹åˆ°é™éŸ³
            silenceFrames++;
            speechFrames = 0;

            // VAD æ¨¡å¼ï¼šå§‹ç»ˆç¼“å†²
            speechBuffer.push(chunk);

            // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡åˆ†
            const silenceDurationMs = silenceFrames * BUFFER_SIZE_MS;
            if (silenceDurationMs >= VAD_CONFIG.minSilenceDurationMs && isSpeaking) {
                const timestamp = (i * BUFFER_SIZE / SAMPLE_RATE).toFixed(2);
                console.log(`ğŸ”‡ [${timestamp}s] æ£€æµ‹åˆ°é™éŸ³ ${silenceDurationMs}msï¼Œæ‰§è¡Œåˆ‡åˆ†`);

                if (speechBuffer.length > 0) {
                    const totalSamples = speechBuffer.reduce((sum, buf) => sum + buf.length, 0);
                    const durationSec = (totalSamples / SAMPLE_RATE).toFixed(2);
                    const sizeKB = (totalSamples * 4 / 1024).toFixed(1);

                    chunkCount++;
                    console.log(`âœ‚ï¸  éŸ³é¢‘å— #${chunkCount} | ${totalSamples} æ ·æœ¬ | ${durationSec}s | ${sizeKB}KB\n`);

                    speechBuffer = [];
                    silenceFrames = 0;
                }

                isSpeaking = false;
            }
        }
    }

    // å¤„ç†å‰©ä½™ç¼“å†²
    if (speechBuffer.length > 0) {
        const totalSamples = speechBuffer.reduce((sum, buf) => sum + buf.length, 0);
        const durationSec = (totalSamples / SAMPLE_RATE).toFixed(2);
        const sizeKB = (totalSamples * 4 / 1024).toFixed(1);

        chunkCount++;
        console.log(`\nâœ‚ï¸  [æœ€å] éŸ³é¢‘å— #${chunkCount} | ${totalSamples} æ ·æœ¬ | ${durationSec}s | ${sizeKB}KB`);
    }

    console.log('\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
    console.log(`\nâœ… æµ‹è¯•å®Œæˆï¼`);
    console.log(`   æ€»åˆ‡ç‰‡æ•°: ${chunkCount}`);
    console.log(`   æ€»å¸§æ•°: ${totalFrames}`);
    console.log(`   éŸ³é¢‘æ—¶é•¿: ${(audioData.length / SAMPLE_RATE).toFixed(2)}s\n`);
}

// ä¸»å‡½æ•°
async function main() {
    const audioPath = process.argv[2] || '/home/tiger/Projects/ASR_pc_front/recording/long_audio_test.wav';

    if (!fs.existsSync(audioPath)) {
        console.error(`âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: ${audioPath}`);
        process.exit(1);
    }

    try {
        const audioData = readWavFile(audioPath);
        await testVAD(audioData);
    } catch (err) {
        console.error('âŒ æµ‹è¯•å¤±è´¥:', err);
        process.exit(1);
    }
}

main().catch(console.error);
