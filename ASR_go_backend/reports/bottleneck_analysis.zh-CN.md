# 性能瓶颈深度分析报告

> **语言切换**: [English](bottleneck_analysis.md) | [简体中文](bottleneck_analysis.zh-CN.md)


**目标**: 解释为何 500 路并发只有 22% 成功率，以及为何这不属于代码 Bug。

---

## 1. 核心结论
目前系统的**软件架构 (Software Architecture)** 已经完全支持高并发（经 10 路测试 100% 成功验证），但**硬件算力/Worker 数量 (Compute Resources)** 严重不足。

**打个比方**: 
*   **Go 后端 (网关)** 就像一个 **如果不限流能容纳 2000 人的火车站大厅**。此次重构修复了门禁（连接数限制）和广播系统（Redis 订阅），所以 500 个人能顺利进站。
*   **Python Worker (消费者)** 就像 **唯一的一个检票员**。
*   **结果**: 500 个人同时涌入，每个人都需要检票。唯一的检票员每处理一个人需要一定时间。排在后面的人等太久（超过 60 秒），就因为**超时 (Timeout)** 而被迫离开了。

---

## 2. 算数证明 (The Math)

根据测试报告数据：
*   **并发数**: 500 用户
*   **Worker 数量**: 1 个
*   **客户端超时设置**: 60 秒

### 实时率 (RTF) 分析
`RTF (Real Time Factor)` 定义为：`处理时间 / 音频时长`。
*   RTF < 1.0: 处理比说话快 (实时)。
*   RTF > 1.0: 处理比说话慢 (非实时)。
*   **理想情况**: FunASR 模型的单流 RTF 通常在 0.05 - 0.2 之间（非常快）。

**但是在 1 个 Worker 面对 500 个并发请求时：**
Worker 必须**串行**或**分时**处理这 500 个请求的任务分片。

假设音频时长 1 秒，单次推理耗时 0.1 秒 (RTF=0.1)。
*   第 1 个切片到达：Worker 处理需 0.1s。
*   第 500 个切片到达：Redis 队列里已经排了 499 个切片。
*   **排队等待时间**: 499 * 0.1s = 49.9s。

如果音频更长一点，或者网络稍微抖动，排在后面的请求等待时间就会超过 **60 秒**。

**测试数据佐证**:
报告显示成功任务的 `Avg RTF` 约为 **52**。
这意味着处理 1 秒的音频，平均耗时 52 秒。
`52秒 (实际耗时) ≈ 0.1秒 (推理) * 500 (并发数)`
这完美吻合 **"1个 Worker 服务 500 人"** 的数学模型。

---

## 3. 为何不是 Bug？

*   **Bug** 是指程序逻辑错误（如死锁、内存泄露、Panic），导致服务崩溃或结果错误。
*   **瓶颈 (Bottleneck)** 是指资源（CPU/GPU/内存）不足以支撑当前负载。

本次测试中：
1.  **Go 后端没有崩**: 成功维持了 500 个 WebSocket 连接，转发了所有数据。
2.  **Redis 没有崩**: 成功处理了所有 Pub/Sub 消息。
3.  **Python Worker 没有崩**: 只要给它时间，它最终能处理完所有任务（只是用户等不起了）。

因此，这是一个典型的 **容量规划 (Capacity Planning)** 问题。

---

## 4. 解决方案：如何达到 100% 成功率？

要解决排队超时，必须增加 "检票员" (Worker)。

### 方法 A: 垂直扩展 (不推荐)
给这一台机器加更强的 CPU/GPU，提高单 Worker 处理速度。但物理单核速度有上限，提升有限。

### 方法 B: 水平扩展 (推荐)
启动更多的 Worker 进程/容器。

**估算公式**:
`所需 Worker 数 = (总并发数 * 单流RTF) / 目标利用率`

假设单流 RTF 为 0.1 (即处理速度是语速的 10 倍)：
*   **500 路并发**: 需要 500 * 0.1 = **50 个 Worker** 才能保证完全实时不排队。
*   如果允许少量排队，至少也需要 **20-30 个 Worker**。

**操作步骤**:
1.  在 `docker-compose.yml` 或 K8s 中将 Worker 副本数设为 50。
2.  或者在物理机上运行 50 个 `python stream_worker.py` 进程。

### 总结
你现在的系统就像用 **一辆法拉利 (Go Backend)** 去拉 **500 吨砖头**，只有 **一个工人 (Python Worker)** 卸货。车没坏，是卸货的人不够。

---

## 5. 优化实施计划 (TODO List)

为了提升用户体验并最终解决瓶颈，建议按以下步骤实施：

### 5.1 短期优化：可视化排队体验 (Queue Visualization)
目标：缓解用户等待焦虑，避免不明真相的超时。业界标准的前端等待处理方案。

- [ ] **Go Backend**: 实现 Redis 队列深度监控
    - [ ] `ASRService` 新增 `GetQueueDepth()` 方法，调用 Redis `LLEN`.
    - [ ] 在 WebSocket 循环中，(如每秒或在接收 Chunk 时) 向客户端推送 `{"type": "queue_status", "pending": 123}` 消息.
- [ ] **Frontend/Client**: 适配排队 UI
    - [ ] 客户端识别 `queue_status` 消息.
    - [ ] 当 `pending > 阈值` 时，UI 展示 "当前排队人数: 123，请稍候...".
- [ ] **Go Backend**: 实现反压保护 (Backpressure)
    - [ ] 在 `handleStart` 建立连接阶段检查队列长度.
    - [ ] 如果 `pending > 5000` (过载保护)，直接拒绝新连接 (返回 HTTP 503)，保护现有用户体验。

### 5.2 长期优化：水平扩展 (Scale Out)
目标：彻底解决排队问题，达成 100% 实时率。

- [ ] **Infrastructure**: 容器化部署
    - [ ] 编写 `docker-compose.yml` 或 K8s 配置.
    - [ ] 定义 Stream Worker 服务副本数 `replicas: 50` (根据 500 并发测算).
- [ ] **Monitoring**: 增强监控
    - [ ] 接入 Prometheus/Grafana 监控 Redis `asr_chunk_queue` 长度.
    - [ ] 监控 Worker 的 CPU 利用率，实现基于负载的自动伸缩 (HPA).
