# 后端监控架构实施计划与思考

**日期**: 2025-12-14
**状态**: 规划中 (Planning)

---

## 1. 核心决策

### 1.1 采用 "心跳机制" (Heartbeat)
*   **决策**: 放弃基于 `XINFO` 的被动监控，采用 Worker 主动上报心跳的方案。
*   **理由**:
    *   我们需要**绝对准确**的存活检测，不能容忍低负载下的误报。
    *   我们拥有 Python Worker 的源码控制权，修改成本低（约 30 行代码）。
    *   这是业界保障高可用性 (HA) 的标准做法。
*   **优化点**: 心跳数据中将携带负载信息（如：已处理任务数、当前队列深度），为未来负载均衡做准备。

### 1.2 暂缓 Prometheus/Grafana 部署
*   **决策**: 将 Prometheus 监控体系列为 **TODO**，暂不立即实施。
*   **理由**:
    *   **优先级**: 当前首要任务是保障 Worker 挂掉时系统不崩（通过心跳 + 降级解决）。
    *   **学习曲线**: 虽然不需要 K8s，但引入 Prometheus 生态仍有一定学习和运维成本。
    *   **当前规模**: 目前单机部署，通过日志和简单的 Redis 命令尚可手动排查问题。
*   **未来触发点**: 当 Worker 数量增加，或者需要进行精细化性能调优时，再启动此计划。

---

## 2. 实施计划 (Action Items)

### Phase 1: 基础高可用保障 (P0 - 立即执行)
目标：让 Go Backend 能感知 Worker 死亡并停止派发任务。

1.  **Python Worker 改造**:
    *   实现后台线程，每 **15秒** 向 Redis 写入心跳 Key。
    *   Key 格式: `worker:{id}:heartbeat`，TTL 设置为 **30秒**。
    *   携带 Payload: `{"ts": 1234567890, "load": ...}`。

2.  **Go Backend 改造**:
    *   实现 `HealthChecker` 模块。
    *   每隔 **15-30秒** 扫描 Redis 中的心跳 Key。
    *   统计存活 Worker 数量。

3.  **分级降级策略**:
    *   **Level 1 (正常)**: 存活 Worker >= 2 -> 正常服务。
    *   **Level 2 (拥塞)**: 存活 Worker < 2 -> 拒绝新连接 (HTTP 503)，保护现有连接。
    *   **Level 3 (停摆)**: 存活 Worker = 0 -> 立即切断所有连接，防止请求堆积。

### Phase 2: 可观测性建设 (P1 - 待定)
目标：通过图表直观展示系统状态。

1.  **部署 Redis Exporter**: 监控 Redis 内存和连接数。
2.  **部署 Prometheus + Grafana**: 使用 Docker Compose 快速拉起。
3.  **接入业务指标**: 统计 RTF (实时率)、队列深度趋势。

---

## 3. 总结

目前的策略是 **"稳字当头"**。先通过简单的代码修改（心跳）解决最致命的 "盲目派单" 问题，确保系统在 Worker 崩溃时能软着陆。对于高大上的监控面板，留待系统规模扩大后再行建设。
