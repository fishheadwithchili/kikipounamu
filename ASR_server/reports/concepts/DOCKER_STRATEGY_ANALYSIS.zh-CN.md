# Docker 策略与持久化分析报告

**日期**: 2025-12-11
**背景**: ASR 后端项目 (高性能, 强依赖 GPU/CUDA)
**硬件环境**: RTX 5060 Ti (Blackwell), CUDA 12.8, PyTorch 2.9.1+

## 1. 问题陈述
项目目前运行在"裸机"（直接运行在宿主机）模式下。我们评估了引入 Docker 的必要性和时机，主要关注以下挑战：
1.  **PostgreSQL 持久化**: 担心 Docker 中数据库数据的安全性及版本不兼容问题。
2.  **资源占用**: 长期不使用时，如何防止 Docker 容器持续占用系统资源。
3.  **AI/CUDA 复杂性**: 在前沿硬件环境下，Docker 是否构成了不必要的阻碍。

## 2. PostgreSQL + Docker 分析

### 澄清
PostgreSQL **完全可以** 在 Docker 生产环境中运行，但对 Volume（卷）管理有严格要求。

### 常见风险
*   **版本升级**: 自动拉取新镜像（如 `postgres:latest` 或跨大版本升级）会导致 "database files are incompatible with server" 错误，容器启动失败。
*   **卷数据丢失**: 错误的 `docker-compose down -v` 命令会彻底删除数据。
*   **权限问题**: Linux 宿主机上常见的 UID/GID 映射错误导致文件不可读写。

### 建议
*   **生产环境**: 推荐使用托管数据库（如 AWS RDS, 阿里云 RDS 等），由云厂商处理运维。
*   **自托管 Docker**:
    *   锁定精确版本号（例如 `postgres:16.1`，绝不要用 `latest`）。
    *   使用 Bind Mounts 绑定到宿主机固定路径（例如 `./data:/var/lib/postgresql/data`），确保数据可见且不随容器删除。
    *   无论部署方式如何，必须配置 **pg_dump 自动备份脚本**。

## 3. AI/CUDA 项目的 "Docker 税"

对于本项目（ASR + CUDA 12.8），Docker 化会带来显著的额外摩擦：

| 特性 | 裸机运行 (当前) | Docker 化 |
| :--- | :--- | :--- |
| **驱动/CUDA 匹配** | 直接调用宿主机驱动 | 需要严格匹配：宿主机驱动 + 容器内 CUDA Toolkit + nvidia-docker 配置 |
| **镜像体积** | 无 (共享系统库) | 巨大 (8GB-10GB)，因为需要打包 CUDA/PyTorch/模型 |
| **模型文件管理** | 共享文件系统 | 必须挂载卷或打入镜像，加载和更新都很慢 |
| **开发循环** | 即时生效 (`--reload`) | 构建 -> 停止 -> 运行 循环 |

**结论**: 针对当前的单机、新硬件开发阶段，**裸机运行远优于 Docker**。

## 4. 资源管理方案

痛点：项目闲置时，Docker 容器会持续占用 RAM/CPU。

### 不推荐方案
*   **Kubernetes (K8s)**: 过度设计。仅控制平面就要占用 1GB+ 内存，且配置极其复杂，对于单体应用性价比极低。

### 推荐方案
1.  **Systemd 服务 (Linux)**:
    *   配置 `RuntimeMaxSec` 限制运行时间。
    *   仅在需要时通过 `systemctl start asr-server` 启动。
2.  **自动休眠脚本**:
    *   编写简单的 Shell 脚本，监控访问日志，无活动 N 分钟后自动停止服务。
3.  **手动控制**:
    *   在开发阶段，手动的 `docker-compose up -d` / `down` 是最直观高效的资源管理方式。

## 5. 战略路线图

### 第一阶段：裸机开发 (当前)
*   **状态**: 推荐保持。
*   **理由**: 完美适配 RTX 5060 Ti，调试最简单，无虚拟化性能损耗。
*   **工具**: `uv` 管理 Python 环境, 本地运行 Redis/Postgres。

### 第二阶段：混合/部分容器化 (准备部署)
*   **触发点**: 部署到远程服务器 或 增加其他开发者时。
*   **动作**:
    *   Redis/DB 放入 Docker 容器。
    *   应用本身保留在宿主机运行（为了方便 GPU 访问）。

### 第三阶段：全容器化
*   **触发点**: 云端大规模部署 (Lambda Labs, RunPod) 或 大规模团队协作。
*   **动作**: 全套 `docker-compose` 或 K8s。必须解决镜像体积巨大和模型缓存的问题。
