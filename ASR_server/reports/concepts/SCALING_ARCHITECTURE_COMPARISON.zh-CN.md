# 扩展架构对比：基于进程 vs Kubernetes

> **语言切换**: [English](SCALING_ARCHITECTURE_COMPARISON.md) | [简体中文](SCALING_ARCHITECTURE_COMPARISON.zh-CN.md)

## 背景
当前的 `ASR_server` 项目使用生产者-消费者模型处理 ASR 任务。该架构通过 Redis 和 RQ (Redis Queue) 将 API 服务器与处理 Worker 解耦。

- **API Server**: 接收 HTTP 请求并入队任务。
- **Workers**: Python 进程，出队并执行任务（ASR 推理）。
- **扩展机制**: 手动或脚本化的 Worker 进程水平扩展。

本文档对比当前的 "基于进程" 扩展策略与 "基于容器" (Kubernetes) 扩展策略，以确定当前阶段的最佳方案。

## 核心机制对比

| 特性 | 当前策略 (Python RQ + Shell) | Kubernetes (K8s HPA) |
| :--- | :--- | :--- |
| **调整触发** | **手动 / 脚本**。扩展需要执行脚本 (如 `start_workers.sh`) 或手动启动进程。"热扩展" 通过即时启动新进程实现。 | **指标驱动**。基于 CPU/内存使用率或自定义指标（如 Redis 队列深度）自动扩展。定义规则如 "若队列 > 100，增加 Pod"。 |
| **隔离性** | **进程级**。Worker 共享宿主 OS 内核和资源。一个 Worker 的内存泄漏可能影响整个系统 (OOM)。 | **容器/Pod 级**。每个 Worker 运行在隔离容器中，有严格的 CPU/内存配额 (Cgroups)。故障逻辑隔离。 |
| **扩展上限** | **单机**。受限于运行应用的单台服务器物理资源（CPU核数/内存）。 | **集群**。可扩展至多个物理节点，取决于预算和集群规模，几乎无限。 |
| **运维成本** | **低**。仅需基础 Linux 知识和 Shell 脚本。无需维护复杂基础设施。 | **高**。需要维护控制面、网络、存储、YAML 配置等。 |
| **响应时间** | **快**。启动 Python 进程只需毫秒级。 | **中等**。调度和启动 Pod（拉取镜像、容器启动）可能需要秒级。 |

## 当前实现："热扩展"
当前设置支持无服务中断的 "热扩展"：
1.  **API 非阻塞**: API 服务器独立于 Worker 数量。即使 0 个 Worker 活跃，它也能继续接收请求。
2.  **动态调整**:
    - **扩容**: 运行 `scripts/start_workers.sh` 或手动生成 `rq worker` 进程以立即增加吞吐量。
    - **缩容**: 终止特定 Worker 进程 (`kill <pid>`) 以释放资源。如果配置得当，Redis 会处理失败任务的重新入队。

## 决策指南：何时切换？

### ✅ 保持当前策略，如果：
*   **单机足够**: 工作负载在垂直扩展服务器（如 64-96 核）的容量范围内。
*   **团队规模/预算**: 资源限制无法提供专门的 DevOps 维护集群。
*   **负载可预测**: 流量模式稳定或可预测（如 "白天高，夜间低"），允许基于 Cron 的定时扩展。
*   **快速迭代**: 早期开发阶段需要频繁的代码变更和简单的部署验证。

### 🚀 切换到 Kubernetes，如果：
*   **资源耗尽**: 单机垂直扩展不再够快或不再具有成本效益。
*   **高可用 (HA)**: 零停机是绝对要求。如果物理节点故障，负载必须自动迁移到另一节点。
*   **极端波动**: 流量在几分钟内从 1 激增到 10,000 并发，需要自动集群自动缩放器 (Cluster Autoscaler) 供应新节点。
*   **多语言微服务**: 系统演变成复杂的服务网格（ASR, LLM, TTS, DB, Cache），需要服务发现和网络策略。

## 结论
当前架构实际上作为一个 "单机编排器" 运行：
- **Redis** 充当控制面 / API Server。
- **RQ Workers** 充当 Pod。
- **Shell 脚本** 充当 ReplicaSet 控制器。

**决策**: 对于当前的规模和需求，基于进程的 RQ 策略是 **最佳选择**。它在尽量减少工程开销的同时，为动态扩展提供了足够的灵活性。仅当多节点分布式处理成为硬性要求时，才应考虑迁移到 K8s。
